{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hello, Local Data Platform!","text":"<p>Welcome to the documentation for local-data-platform, a Python library to build, test, and run a complete data platform on your local machine.</p> <p>The core idea is to provide a \"toy box for data\"\u2014a local environment where you can manage the entire data lifecycle, from ingestion to reporting, before needing to scale up to a cloud environment.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>User Guide &amp; Recipes: Practical examples and step-by-step guides to help you use the library.</li> <li>API Reference: Detailed information on the classes, functions, and modules.</li> </ul> <p>We hope you find this documentation helpful!</p>"},{"location":"api/","title":"API Reference","text":"<p>This section contains the auto-generated API reference for the project.</p>"},{"location":"api/#hello-world","title":"Hello World","text":"<p>A simple module to demonstrate library functionality.</p>"},{"location":"api/#local_data_platform.hello_world.hello_world","title":"<code>hello_world()</code>","text":"<p>Prints 'Hello, world!' to the console.</p> <p>This is a sample function to show how docstrings are rendered in the documentation.</p> Source code in <code>src/local_data_platform/hello_world.py</code> <pre><code>def hello_world():\n    \"\"\"Prints 'Hello, world!' to the console.\n\n    This is a sample function to show how docstrings are rendered in the\n    documentation.\n    \"\"\"\n    print(\"Hello, world!\")\n</code></pre>"},{"location":"api/#core-modules","title":"Core Modules","text":"<p>Handles logging configuration for the local-data-platform library.</p> <p>This module sets up a simple logger that can be used across the library to provide consistent and configurable logging output.</p>"},{"location":"api/#local_data_platform.exceptions.TableNotFound","title":"<code>TableNotFound</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when accessing a table that doesn't exist</p> Source code in <code>src/local_data_platform/exceptions.py</code> <pre><code>class TableNotFound(Exception):\n    \"\"\"Raised when accessing a table that doesn't exist\"\"\"\n</code></pre>"},{"location":"api/#local_data_platform.exceptions.PipelineNotFound","title":"<code>PipelineNotFound</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when running a pipeline that doesn't exist</p> Source code in <code>src/local_data_platform/exceptions.py</code> <pre><code>class PipelineNotFound(Exception):\n    \"\"\"Raised when running a pipeline that doesn't exist\"\"\"\n</code></pre>"},{"location":"api/#local_data_platform.exceptions.EngineNotFound","title":"<code>EngineNotFound</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when engine is not supported</p> Source code in <code>src/local_data_platform/exceptions.py</code> <pre><code>class EngineNotFound(Exception):\n    \"\"\"Raised when engine is not supported\"\"\"\n</code></pre>"},{"location":"api/#local_data_platform.exceptions.PlanNotFound","title":"<code>PlanNotFound</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when issue doesn't have resolution estimate</p> Source code in <code>src/local_data_platform/exceptions.py</code> <pre><code>class PlanNotFound(Exception):\n    \"\"\"Raised when issue doesn't have resolution estimate\"\"\"\n</code></pre>"},{"location":"api/#store","title":"Store","text":""},{"location":"api/#pipeline","title":"Pipeline","text":"<p>A data pipline captures data from the source and stores it your target storage</p>"},{"location":"developer_feature_requests/","title":"Requesting Developer Features","text":"<p>Have an idea for a new feature or an improvement? We'd love to hear it! Contributing ideas is a great way to help shape the future of the <code>local-data-platform</code>.</p>"},{"location":"developer_feature_requests/#how-to-suggest-a-feature","title":"How to Suggest a Feature","text":"<p>To suggest a new feature, please use our \"Feature request\" template on GitHub. This helps us gather all the necessary information to understand and evaluate the proposal.</p> <p>Request a New Feature</p> <p>When submitting a feature request, please consider the following: - A clear description of the problem your feature solves. - A detailed explanation of the proposed solution. - Any alternative solutions you have considered.</p>"},{"location":"pr_description/","title":"Pull Request Description: Documentation and Testing Improvements","text":""},{"location":"pr_description/#summary","title":"Summary","text":"<p>This pull request enhances the documentation and testing for the <code>local-data-platform</code> project. The main improvements include:</p> <ul> <li>Adding a <code>recipes.md</code> page to the documentation, featuring practical usage examples such as reading a JSON file and building a JSON-to-Parquet pipeline.</li> <li>Ensuring the recipes page appears in the sidebar/main navigation for easier access.</li> <li>Updating Sphinx and Markdown documentation structure for improved navigation and clarity.</li> <li>Adding a test (<code>tests/test_json_source.py</code>) to verify that the <code>JsonSource</code> class can read a JSON file as described in the documentation.</li> <li>Maintaining compatibility for documentation builds both locally and on Read the Docs.</li> </ul>"},{"location":"pr_description/#how-to-test","title":"How to Test","text":"<ul> <li> <p>Build the documentation locally:   <pre><code>cd docs\nmake html\n</code></pre>   Verify that the \"Recipes\" page appears in the sidebar and renders correctly.</p> </li> <li> <p>Run the test suite to ensure the new test passes:   <pre><code>pytest tests/test_json_source.py\n</code></pre></p> </li> </ul>"},{"location":"pr_description/#notes","title":"Notes","text":"<ul> <li>Please review the import paths and class names in the recipes and test to ensure they match your implementation.</li> <li>Further enhancements or additional recipes/tests can be added as needed.</li> </ul>"},{"location":"recipes/","title":"Local Data Platform Recipes","text":"<p>This page contains practical recipes for using the local-data-platform library.</p>"},{"location":"recipes/#recipe-read-a-json-file","title":"Recipe: Read a JSON File","text":"<p>You can read a JSON file using the <code>local-data-platform</code> library as follows:</p> <pre><code>from local_data_platform.store.source.json import JsonSource\n\n# Initialize the JSON source with your file path\njson_source = JsonSource(path=\"path/to/your/file.json\")\n\n# Read the data\n# (use .get() or .read() depending on your implementation)\ndata = json_source.get()\n\nprint(data)\n</code></pre> <p>Replace <code>path/to/your/file.json</code> with the path to your JSON file. The exact class/method may differ depending on your implementation.</p>"},{"location":"recipes/#recipe-json-to-parquet-data-pipeline","title":"Recipe: JSON to Parquet Data Pipeline","text":"<p>This example demonstrates how to build a simple pipeline that reads data from a JSON file and writes it to a Parquet file using the local-data-platform library.</p> <pre><code>from local_data_platform.store.source.json import JsonSource\nfrom local_data_platform.store.target.parquet import ParquetTarget\nfrom local_data_platform.pipeline.ingestion.json_to_parquet import JsonToParquetPipeline\n\n# Initialize source and target\njson_source = JsonSource(path=\"data/input.json\")\nparquet_target = ParquetTarget(path=\"data/output.parquet\")\n\n# Create and run the pipeline\npipeline = JsonToParquetPipeline(source=json_source, target=parquet_target)\npipeline.run()\n</code></pre> <p>Make sure to replace the class names and import paths with the actual ones from your implementation. This assumes you have a pipeline class like <code>JsonToParquetPipeline</code>.</p>"},{"location":"recipes/#sample-json-file","title":"Sample JSON File","text":"<pre><code>[\n  {\"id\": 1, \"name\": \"Alice\", \"score\": 95},\n  {\"id\": 2, \"name\": \"Bob\", \"score\": 88},\n  {\"id\": 3, \"name\": \"Charlie\", \"score\": 92}\n]\n</code></pre> <p>Save this as <code>data/input.json</code> to test the pipeline.</p>"},{"location":"user_issues/","title":"Reporting User Issues","text":"<p>{% include \"includes/user_issues_list.md\" %}</p>"},{"location":"user_issues/#how-to-report-new-issue","title":"How to Report New Issue","text":"<p>If you encounter a bug, have a question, or are facing any problems using the library, please let us know by creating an issue on our GitHub repository.</p> <p>Report an Issue on GitHub</p> <p>When creating an issue, please provide as much detail as possible, including: - A clear and descriptive title. - The version of the library you are using. - Steps to reproduce the problem. - Any relevant error messages or logs.</p>"},{"location":"user_issues/#user-stories","title":"User Stories","text":"<p>If you want to provide user stories then follow this template. -  As a user, -  I want a way to do X, -  So that I can achieve Y</p>"},{"location":"includes/issue_list/","title":"Issue list","text":"<p>{% include \"user_issues.md\" %}</p>"},{"location":"includes/user_issues_list/","title":"User issues list","text":""},{"location":"includes/user_issues_list/#currently-open-issues","title":"Currently Open Issues","text":"<ul> <li>#91 - Docs sidebar recipes</li> <li>#90 - Fix readthedocs</li> <li>#89 - Event driven User behaviour Analysis</li> <li>#88 - Optimistic Concurrency Iceberg</li> <li>#87 - Bump jinja2 from 3.1.4 to 3.1.5 in /docs in the pip group across 1 directory</li> <li>#83 - V0.1.1 : pytest for BigQueryToCSV.extract()</li> <li>#82 - V0.1.1 Adding pytest for bigquery</li> <li>#75 - A python function to pull data from Snowflake</li> <li>#59 - 0.1.8 Query this catalog through prompt </li> <li>#57 - 0.1.2 Warehousing: add duckdb, dbt and iceberg packages </li> <li>#55 - 0.1.2 warehousing using dbt, duckdb and iceberg</li> <li>#50 - 0.1.3 Orchestration: cron and airflow</li> <li>#48 - 0.1.2 Warehousing: Excel to csv support</li> <li>#47 - 0.1.2 Reoccurring Customer Churn Analysis</li> <li>#45 - 0.1.4 DBT Transformation layer </li> <li>#44 - 0.1.3 Orchestration using cron</li> <li>#42 - 0.1.3 Orchestration: using airflow</li> <li>#38 - 0.1.1 Demo: Questions by end user</li> <li>#33 - 0.1.1 Documentation: Read The Docs</li> <li>#29 - 0.1.1 Align on Product Framework</li> <li>#28 - 0.2.0 Product Requirements</li> <li>#27 - 0.1.9 Blog the class diagram</li> <li>#23 - 0.1.2 Implement Partitioning and Version Control</li> <li>#19 - 0.1.1 Create a Google BigQuery Client\u2028</li> <li>#13 - 0.2.0 DosuBot : Github maintainer </li> <li>#5 - 0.1.1 Setup Wiki</li> </ul>"}]}